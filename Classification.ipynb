{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of chronic kidney diseance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import models as m\n",
    "from model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "       ...        pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
       "0      ...         44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
       "1      ...         38  6000  NaN   no   no   no  good   no   no            ckd  \n",
       "2      ...         31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
       "3      ...         32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
       "4      ...         35  7300  4.6   no   no   no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/kidney_disease.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/preprocessed.csv'\n",
    "target_name = 'Class'\n",
    "test_size= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (280, 24)  y_train : (280,) X_test :  (120, 24) y test :  (120,)\n"
     ]
    }
   ],
   "source": [
    "df, X, y, X_train, X_test, y_train, y_test = load_data(path, target_name, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_train = label_binarize(y_train, classes = ['ckd', 'notckd'])\n",
    "y_test = label_binarize(y_test, classes = ['ckd', 'notckd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first train a decision tree classifier with default parameters and evaluate it's preformance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = X_train, y_train\n",
    "Decision_clf = m.DecisionTreeModel( train = True, X_train= X_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[79  2]\n",
      " [ 2 37]]\n",
      "Accuracy :  96.66666666666667\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        81\n",
      "           1       0.95      0.95      0.95        39\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.97      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict(Decision_clf, X_test)\n",
    "accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accuracy : 0.97\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation(Decision_clf, X,y,epochs=100, batch_size=70, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters tunig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.DecisionTreeModel( train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],  \n",
    "              'max_depth' : range(1,10),\n",
    "              'min_samples_leaf': range(1,10) } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:    2.5s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gs, fitted_model, pred = search_pipeline(X_train, X_test, y_train, model, param_grid ,scoring_fit = 'accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramÃ¨tres sont  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1}\n",
      "les meilleur score est  0.9857142857142858\n",
      "Confusion Matrix: \n",
      " [[79  2]\n",
      " [ 2 37]]\n",
      "Accuracy :  96.66666666666667\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        81\n",
      "           1       0.95      0.95      0.95        39\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.97      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_parameters = get_best_parameters (gs )\n",
    "y_pred = m.predict(fitted_model, X_test)\n",
    "accuracy(y_test, y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.6110 - accuracy: 0.6857 - val_loss: 0.3883 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "280/280 [==============================] - 0s 58us/step - loss: 0.2359 - accuracy: 0.9000 - val_loss: 0.1591 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "280/280 [==============================] - 0s 67us/step - loss: 0.1252 - accuracy: 0.9464 - val_loss: 0.1289 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "280/280 [==============================] - 0s 71us/step - loss: 0.0913 - accuracy: 0.9786 - val_loss: 0.1075 - val_accuracy: 0.9667\n",
      "Epoch 5/20\n",
      "280/280 [==============================] - 0s 69us/step - loss: 0.0705 - accuracy: 0.9821 - val_loss: 0.0525 - val_accuracy: 0.9917\n",
      "Epoch 6/20\n",
      "280/280 [==============================] - 0s 67us/step - loss: 0.0549 - accuracy: 0.9857 - val_loss: 0.0475 - val_accuracy: 0.9917\n",
      "Epoch 7/20\n",
      "280/280 [==============================] - 0s 72us/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "280/280 [==============================] - 0s 67us/step - loss: 0.0430 - accuracy: 0.9893 - val_loss: 0.0421 - val_accuracy: 0.9917\n",
      "Epoch 9/20\n",
      "280/280 [==============================] - 0s 65us/step - loss: 0.0265 - accuracy: 0.9893 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
      "Epoch 10/20\n",
      "280/280 [==============================] - 0s 62us/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "280/280 [==============================] - 0s 65us/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "280/280 [==============================] - 0s 66us/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "280/280 [==============================] - 0s 70us/step - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.0252 - val_accuracy: 0.9917\n",
      "Epoch 14/20\n",
      "280/280 [==============================] - 0s 69us/step - loss: 0.0628 - accuracy: 0.9786 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "280/280 [==============================] - 0s 62us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9583\n",
      "Epoch 16/20\n",
      "280/280 [==============================] - 0s 65us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9833\n",
      "Epoch 17/20\n",
      "280/280 [==============================] - 0s 64us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "280/280 [==============================] - 0s 62us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "280/280 [==============================] - 0s 72us/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "280/280 [==============================] - 0s 65us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "MLP = m.build_MLP((24,))\n",
    "history = m.train_nn(MLP,X_train, y_train, X_test, y_test, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 39]]\n",
      "Accuracy :  100.0\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        39\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict(MLP, X_test)\n",
    "accuracy(y_test, (y_pred>0.5).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accuracy : 0.9949874877929688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99248123, 0.99248123])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(lambda : m.build_MLP((24,)), X,y,epochs=20, batch_size=70, n_splits=3, is_keras_model= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'epochs':[5, 10, 15 ],\n",
    "              'batch_size':[ 70, 50, 60, 40],\n",
    "              'epochs' :              [100,150,200],\n",
    "              #'batch_size' :          [32, 128],\n",
    "              #'optimizer' :           ['Adam'],\n",
    "              #'dropout_rate' :        [0.1, 0.2, 0.3],\n",
    "              #'activation' :          ['relu', 'elu']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "gs, fitted_model, pred = search_pipeline(X_train, X_test, y_train,lambda : m.build_MLP((24,)), \n",
    "                                         param_grid ,scoring_fit = 'accuracy', is_keras_model = True \n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramÃ¨tres sont  {'batch_size': 40, 'epochs': 200}\n",
      "les meilleur score est  0.9964285714285714\n",
      "Confusion Matrix: \n",
      " [[78  3]\n",
      " [ 0 39]]\n",
      "Accuracy :  97.5\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        81\n",
      "           1       0.93      1.00      0.96        39\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       120\n",
      "   macro avg       0.96      0.98      0.97       120\n",
      "weighted avg       0.98      0.97      0.98       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_parameters = get_best_parameters (gs )\n",
    "y_pred = m.predict(fitted_model, X_test)\n",
    "accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accuracy : 0.9649497071901957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98507464, 0.97744364, 0.93233085])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(lambda : m.build_MLP((24,)), X,y, n_splits=3, is_keras_model= True, **best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = m.build_CNN(input_shape = (24,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_MLP = {\n",
    "              'epochs':[5, 10, 15 ],\n",
    "              'batch_size':[ 70, 50, 60, 40],\n",
    "              \n",
    "              #'batch_size' :          [32, 128],\n",
    "              #'optimizer' :           ['Adam'],\n",
    "              #'dropout_rate' :        [0.1, 0.2, 0.3],\n",
    "              #'activation' :          ['relu', 'elu']\n",
    "             }\n",
    "param_grid_Dt = {'criterion': ['gini', 'entropy'],  \n",
    "              'max_depth' : range(3,14),\n",
    "              'min_samples_leaf': range(3,4) } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \n",
    "target_name =\n",
    "test_size =\n",
    "train =\n",
    "epochs = \n",
    "batch_size = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_MLP = {\n",
    "              'epochs':[5, 10, 15 ],\n",
    "              'batch_size':[ 70, 50, 60, 40],\n",
    "              \n",
    "              #'batch_size' :          [32, 128],\n",
    "              #'optimizer' :           ['Adam'],\n",
    "              #'dropout_rate' :        [0.1, 0.2, 0.3],\n",
    "              #'activation' :          ['relu', 'elu']\n",
    "             }\n",
    "param_grid_Dt = {'criterion': ['gini', 'entropy'],  \n",
    "              'max_depth' : range(3,14),\n",
    "              'min_samples_leaf': range(3,4) } \n",
    "\n",
    "models = {'MLP': {'build_fn':m.build_MLP((24,)),'params': param_grid_MLP},\n",
    "          'Decision_tree' : { 'build_fn':m.DecisionTreeModel( train = False),'params': param_grid_Dt}         \n",
    "         }\n",
    "model_name = 'MLP'\n",
    "finetune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (280, 24)  y_train : (280,) X_test :  (120, 24) y test :  (120,)\n"
     ]
    }
   ],
   "source": [
    "df, X, y, X_train, X_test, y_train, y_test = load_data(path, target_name, test_size)\n",
    "y_train = label_binarize(y_train, classes = ['ckd', 'notckd'])\n",
    "y_test = label_binarize(y_test, classes = ['ckd', 'notckd'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (280, 24)  y_train : (280,) X_test :  (120, 24) y test :  (120,)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramÃ¨tres sont  {'batch_size': 40, 'epochs': 10}\n",
      "les meilleur score est  0.9892857142857143\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 1 38]]\n",
      "Accuracy :  99.16666666666667\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        81\n",
      "           1       1.00      0.97      0.99        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "avg accuracy : 0.9925000011920929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import models as m\n",
    "from model_selection import *\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('Parameter tuning for classification on a defined dataset')\n",
    "parser.add_argument('--path', type=str, default='none')\n",
    "parser.add_argument('--target_name', type=str, default='Class')\n",
    "parser.add_argument('--test_size', type=float, default=0.3)\n",
    "parser.add_argument('--train', type=bool, default='true')\n",
    "parser.add_argument('--batch_size', type=int, default=70)\n",
    "parser.add_argument('--epochs', type=int, default=15)\n",
    "parser.add_argument('--model_name', type=str, default='MLP')\n",
    "parser.add_argument('--finetune', type=bool, default='false')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "path = args.path\n",
    "target_name = args.target_name\n",
    "test_size =args.test_size\n",
    "train = args.train\n",
    "epochs = args.epochs\n",
    "batch_size = args.batch_size\n",
    "model_name = args.model_name\n",
    "finetune = model.finetune\n",
    "\n",
    "df, X, y, X_train, X_test, y_train, y_test = load_data(path, target_name, test_size)\n",
    "y_train = label_binarize(y_train, classes = ['ckd', 'notckd'])\n",
    "y_test = label_binarize(y_test, classes = ['ckd', 'notckd'])\n",
    "\n",
    "models = {'MLP': {'build_fn':lambda : m.build_MLP((24,)),'params': param_grid_MLP},\n",
    "          'Decision_tree' : { 'build_fn':m.DecisionTreeModel( train = False),'params': param_grid_Dt}         \n",
    "         }\n",
    "param_grid_MLP = {\n",
    "              'epochs':[5, 10, 15 ],\n",
    "              'batch_size':[ 70, 50, 60, 40],\n",
    "              \n",
    "              #'batch_size' :          [32, 128],\n",
    "              #'optimizer' :           ['Adam'],\n",
    "              #'dropout_rate' :        [0.1, 0.2, 0.3],\n",
    "              #'activation' :          ['relu', 'elu']\n",
    "             }\n",
    "param_grid_Dt = {'criterion': ['gini', 'entropy'],  \n",
    "              'max_depth' : range(3,14),\n",
    "              'min_samples_leaf': range(3,4) } \n",
    "\n",
    "\n",
    "if finetune :\n",
    "    \n",
    "    model = models[model_name]['build_fn']\n",
    "    param_grid = models[model_name]['params']\n",
    "    gs, fitted_model, pred = search_pipeline(X_train, X_test, y_train,  model, param_grid ,scoring_fit = 'accuracy', is_keras_model = True )\n",
    "    best_parameters = get_best_parameters(gs )\n",
    "    y_pred = m.predict(fitted_model, X_test)\n",
    "    accuracy(y_test, y_pred>0.5)\n",
    "    results = cross_validation( model, X,y, n_splits=10, is_keras_model = True,  **best_parameters)\n",
    "\n",
    "             \n",
    "             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "X_train : (280, 24)  y_train : (280,) X_test :  (120, 24) y test :  (120,)\n",
      "2019-11-30 02:54:51.394269: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-30 02:54:51.407754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faf0ba03430 executing computations on platform Host. Devices:\n",
      "2019-11-30 02:54:51.407784: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=5 .........................................\n",
      "[CV] batch_size=70, epochs=10 ........................................\n",
      "sklearn.externals.joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 528, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 144, in fit\n",
      "    if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "AttributeError: 'KerasClassifier' object has no attribute 'loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"classify.py\", line 56, in <module>\n",
      "    gs, fitted_model, pred = search_pipeline(X_train, X_test, y_train,  model, param_grid ,scoring_fit = 'accuracy' )\n",
      "  File \"/Users/amineouasfi/Desktop/Project_ML/model_selection.py\", line 94, in search_pipeline\n",
      "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 722, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 1191, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 711, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 930, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 833, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 521, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 432, in result\n",
      "    return self.__get_result()\n",
      "  File \"/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "AttributeError: 'KerasClassifier' object has no attribute 'loss'\n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py --path './data/preprocessed.csv' --model_name 'MLP' --finetune True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97500002, 1.        , 1.        , 1.        ,\n",
       "       0.94999999, 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
